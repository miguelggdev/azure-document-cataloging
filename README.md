# Proyecto ‚Äì Entrenamiento de un modelo ML con Azure Machine Learning y scikit-learn

## üìå Descripci√≥n
Este proyecto demuestra el uso de **Azure AI**para para dise√±ar, implementar y justificar una soluci√≥n de clasificaci√≥n autom√°tica de documentos PDF, utilizando Modelos de Lenguaje de Gran Escala (LLMs), 
Consumidos / desplegados en Microsoft Azure.

## Caso de uso del proyecyo 

Una organizaci√≥n recibe diariamente documentos en formato PDF (oficios, contratos, resoluciones, quejas, informes t√©cnicos, etc.) que deben ser clasificados manualmente para su gesti√≥n interna. 

**Problemas actuales:**

- Procesos manuales lentos
- Errores de clasificaci√≥n
- Dificultad para escalar el volumen documental
- Dependencia de personal especializado

**Necesidad**
Automatizar la clasificaci√≥n inicial de documentos para facilitar su enrutamiento, priorizaci√≥n y an√°lisis posterior.

## Objetivos del proyecto

Dise√±ar una soluci√≥n basada en LLMs que permita:

- Extraer texto desde documentos PDF
- Analizar su contenido sem√°ntico
- Clasificar autom√°ticamente el documento en una categor√≠a definida
- Generar una justificaci√≥n legible de la clasificaci√≥n
- Ejecutarse Azure, de forma reproducible

**Categor√≠as de clasificaci√≥n**
Se puede usar estas u otras (deben documentarse):

- Queja / Reclamo
- Contrato
- Resoluci√≥n administrativa
- Informe t√©cnico
- Comunicaci√≥n interna

## Actividades de desarrollo

# Actividad 1 Selecci√≥n del ambiente de ejecuci√≥n

Para el desarrollo de este proyecto **se eligi√≥ la modalidad Azure, utilizando servicios de Azure AI**, principalmente Azure Document Intelligence para la extracci√≥n de texto desde documentos PDF y Azure OpenAI para el an√°lisis sem√°ntico y la clasificaci√≥n autom√°tica.

# Actividad 2 Dise√±o de la soluci√≥n (funcional)

**Contexto del problema**

La organizaci√≥n recibe diariamente documentos en formato PDF (quejas, contratos, resoluciones, informes, comunicaciones internas) que deben ser clasificados manualmente,  lo cual genera un cuello de botella en la clasificacion de documentos generando demoras, errores y dificultad para escalar el proceso.

**Objetivo funcional**

Realizar una solucion de IA con Azure para automatizar la clasificaci√≥n inicial de documentos PDF para lograr facilitar su gesti√≥n, priorizaci√≥n y an√°lisis posterior.

**Soluci√≥n propuesta**

Se propone desarrollar una soluci√≥n que permita:

- Cargar documentos PDF de diferentes tipos
- Extraer autom√°ticamente el texto del documento
- Analizar su contenido sem√°ntico
- Clasificar el documento en una categor√≠a definida
- Generar una justificaci√≥n clara de la clasificaci√≥n

De esta manera, se reduce la intervenci√≥n manual y se mejora la eficiencia del proceso documental.

# Actividad 3 Dise√±o de la soluci√≥n (t√©cnico)

Se opta por una arquitectura basada en eventos y serverless, donde la carga de documentos desencadena autom√°ticamente el procesamiento y clasificaci√≥n.

![arquitectura](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/arquitectura.png)

**- Ingesta de documentos:**
Se cargan documentos en un Blob desde la consola de Azure o CLI

**- Extracci√≥n de texto:**
Se utiliza Azure AI Document Intelligence para extraer texto desde documentos PDF.

**- Preprocesamiento:**
El texto extra√≠do se limpia y normaliza para facilitar su an√°lisis.

**- An√°lisis sem√°ntico y clasificaci√≥n:**
El texto procesado se env√≠a a un modelo de lenguaje de Azure OpenAI, el cual clasifica el documento y genera una justificaci√≥n basada en su contenido.

**- Generaci√≥n de resultados:**
El resultado final se estructura en un formato legible (JSON), que puede ser utilizado por otros sistemas o procesos posteriores.

![Flujo-de-trabajo](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/flujo_trabajo.png)

# Actividad 4 ‚Äì Selecci√≥n y uso del LLM

**Modelo seleccionado**

Se utiliza un modelo de lenguaje grande (LLM) proporcionado por Azure OpenAI, como GPT-4

**Justificaci√≥n del uso del LLM**

- Permite comprender el contenido sem√°ntico del documento.
- Se adapta a diferentes tipos de documentos sin necesidad de entrenamiento adicional.
- Genera clasificaciones explicables y coherentes.


# Actividad 5 ‚Äì Configuraci√≥n del entorno

**Definici√≥n del entorno**

Para este proyecto el entorno de ejecucion se define como Servicio de IA gestionado (PaaS), usando Azure AI Document Intelligence yAzure OpenAI. 
El codigo se desarrolla para python, pero se ejecuta y procesa con Azure 
Dependencias declaradas en requirements.txt
Manejo de credenciales mediante variables de entorno
Separaci√≥n clara entre c√≥digo fuente, datos de entrada y resultados

**Creaci√≥n del Resource Group (Azure CLI)**

Crear un grupo de recursos para la soluci√≥n

```bash
az group create \
  --name rg-ia-clasificacion-documental \
  --location eastus
```
![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/grupo_recursos.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/grupo_recursos2.jpg)

**Creaci√≥n Almacenamiento de datos Azure Blob Storage**
![contenedores](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/contenedor.jpg)

![contenedores](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/contenedores_creados.jpg)

**Gesti√≥n de dependencias**

El proyecto est√° estructurado para ejecutarse en un entorno Python y define sus dependencias en el archivo requirements.txt, lo que permite recrear el entorno de forma controlada:

```python
openai
azure-ai-formrecognizer
python-dotenv
tiktoken
```
Estas librer√≠as permiten:

- Conectarse a Azure OpenAI
- Extraer texto desde PDFs usando Azure AI
- Manejar variables de entorno de forma segura
- Controlar la longitud del texto enviado al modelo

Manejo de variables de entorno

Las credenciales de los servicios Azure se gestionan mediante variables de entorno, evitando la exposici√≥n de informaci√≥n sensible en el c√≥digo.

El proyecto incluye un archivo de referencia .env.example:

```python
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_KEY=
AZURE_OPENAI_DEPLOYMENT=
FORM_RECOGNIZER_ENDPOINT=
FORM_RECOGNIZER_KEY=
```
**Crear Azure AI Document Intelligence (OCR)**

Azure Portal:
Buscar Azure AI Document Intelligence
Crear nuevo recurso
Seleccionar:
Resource Group: rg-ia-clasificacion-pdf
Regi√≥n
Plan: Standard (S0)
Crear

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/documentIntell.jpg)

**Crear Azure OpenAI (LLM)**
Azure Portal:
Buscar Azure OpenAI
Crear recurso
Seleccionar:
Resource Group: rg-ia-clasificacion-pdf
Regi√≥n
Crear

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/OpenAI.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/OpenAI2.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/OpenAI3.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/OpenAI4.jpg)

Ir al Portal de Foundry

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/project.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/foundry.jpg)


 Seleccionar el proyecto correcto
 y verificar:

Subscription: Azure subscription 1
Project: projectdocumental
Resource Group: rg-ia-clasificacion-documental

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/foundry2.jpg)

**Ir a Deployments / Implementaciones**

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/foundry3.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/foundry4.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/foundry5.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/foundry6.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/foundry7.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry8.jpg)


![grupo-drecursos](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots//keys_endpoinst.jpg)

# Actividad 6 Ingesta de documentos PDF

Para el proyecto se propone realizar la ingesta de documentos en un Blob Storage para centralizar la carga de documentos PDF y habilitar el procesamiento autom√°tico por eventos.

Se utiliza Azure Blob Storage como repositorio de entrada.

Se crea un contenedor llamado input-pdfs.
Los documentos PDF son cargados manualmente o v√≠a CLI.
Cada carga de archivo genera un evento de almacenamiento.

contenedor
![contenedor](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/contenedor.jpg)

![contenedor](https://github.com/miguelggdev/azure-document-cataloging/blob/main/project--azure-document-cataloging/screenshots/contenedores_creados.jpg)


# Actividad 6 ‚Äì Clasificaci√≥n documental con Azure OpenAI

Se implementa la clasificaci√≥n autom√°tica de documentos utilizando Azure OpenAI, a partir del texto previamente extra√≠do desde los archivos PDF.

El modelo de lenguaje analiza el contenido completo del documento y determina:

- La categor√≠a documental
- Una justificaci√≥n breve basada en el contenido
- Realizar la clasificaci√≥n sem√°ntica
- Categor√≠as definidas

Las categor√≠as manejadas por la soluci√≥n son:

- Contrato
- Queja
- Resoluci√≥n
- Informe
- Comunicaci√≥n
- Otro


**Enfoque t√©cnico**

El flujo de clasificaci√≥n se basa en:

- Carga del archivo al Blob
- Recepci√≥n del texto extra√≠do del PDF
- Env√≠o del texto a un deployment de Azure OpenAI
- Uso de un prompt estructurado para guiar la respuesta
- Json de Salida

# Actividad 7 - Extraccion del texto

El documento PDF subido al Blob se transforma en texto estructurado para ser entregado el LLM

FLUJO PASO A PASO DE LA EXTRACCI√ìN
- Se detecta el archivo PDF se sube a Blob Storage y se dispara la Azure Function (Blob Trigger)
- Se env√≠a el PDF a Document Intelligence, el archivo se abre en binario y se env√≠a al endpoint del servicio
- Azure analiza el documento  y realiza el reconocimiento de texto
- Se recupera el resultado, Azure devuelve un objeto estructurado, se recorren p√°ginas ‚Üí l√≠neas
- Se concatena el texto y queda listo para procesar por el LLM

# Actividad 8 ‚Äì Preprocesamiento del texto

En esta actividad se realiza el preprocesamiento b√°sico del texto extra√≠do desde los documentos PDF, con el objetivo de normalizar y preparar la informaci√≥n antes de enviarla al modelo de lenguaje para inferencia.

El preprocesamiento permite:

Reducir ruido en el texto
Garantizar entradas consistentes al modelo
Mejorar la calidad de la clasificaci√≥n
Alcance del preprocesamiento
Para la prueba t√©cnica se implementa un preprocesamiento ligero, alineado con buenas pr√°cticas y sin sobreingenier√≠a.

Incluye:

Limpieza de espacios innecesarios
Normalizaci√≥n b√°sica del texto
Preparaci√≥n del contenido para inferencia


# Actividad 8 

El texto preprocesado se obtiene a partir del texto plano generado por Azure Document Intelligence y se procesa mediante funciones simples en Python, manteniendo la trazabilidad del contenido original.

src/preprocess.py

```python
import re

def preprocess_text(text):
    """
    Normaliza el texto extra√≠do del documento para
    dejarlo listo para inferencia con el modelo de lenguaje.
    """

    # Elimina saltos de l√≠nea
    text = text.replace("\n", " ")

    # Reemplaza m√∫ltiples espacios por uno solo
    text = re.sub(r"\s+", " ", text)

    # Elimina espacios al inicio y al final
    text = text.strip()

    return text
```
# Actividad 9

En esta actividad se dise√±a un prompt estructurado para guiar al modelo de lenguaje (Azure OpenAI) en la clasificaci√≥n documental, definiendo roles, categor√≠as cerradas y un formato de salida en JSON.

El prompt define expl√≠citamente:

- El rol del modelo
- Las categor√≠as permitidas
- El formato de salida
- El contexto del documento

Objetivo del prompt

El prompt tiene como objetivo que el modelo:

Analice el contenido completo del documento

Determine la categor√≠a documental m√°s adecuada

Explique brevemente la raz√≥n de la clasificaci√≥n

Retorne una salida estructurada y procesable

Principios de dise√±o del prompt

El dise√±o del prompt sigue buenas pr√°cticas para LLMs:

- Claridad: instrucciones directas y sin ambig√ºedad
- Restricci√≥n: categor√≠as cerradas
- Estructura: salida en formato JSON

**Prompt definitivo utilizado en la soluci√≥n**

 Este prompt es el que se utiliza en classify.py
```python
*Eres un asistente experto en clasificaci√≥n documental.

Analiza el siguiente texto y clasif√≠calo en UNA de las siguientes categor√≠as:
- Contrato
- Queja
- Resoluci√≥n
- Informe
- Comunicaci√≥n
- Otro

Devuelve √∫nicamente un JSON con esta estructura:
{
  "categoria": "<categoria>",
  "justificacion": "<explicacion breve basada en el contenido>"
}

Texto del documento:
{document_text}*
```


Justificaci√≥n de la soluci√≥n

Se eligi√≥ un prompt estructurado porque:

- Reduce variabilidad del modelo
- Aumenta la confiabilidad del resultado
- Facilita integraci√≥n con otros sistemas
- Permite explicar cada decisi√≥n del modelo

**Resultado de la actividad**

‚úî Prompt claro y documentado
‚úî Salida estructurada
‚úî Clasificaci√≥n explicable
‚úî F√°cil de mantener y extender


# Actividad 10

En esta actividad se ejecuta la clasificaci√≥n final de los documentos utilizando un modelo de lenguaje desplegado en Azure OpenAI.
El texto, previamente extra√≠do y preprocesado, es enviado al LLM, el cual retorna:

La categor√≠a documental

Una justificaci√≥n explicable

La respuesta del modelo se recibe en un formato estructurado (JSON), permitiendo su uso posterior en sistemas de almacenamiento, visualizaci√≥n o automatizaci√≥n.

Flujo completo de clasificaci√≥n

El flujo de esta actividad integra todas las etapas anteriores:

PDF
 ‚Üì
Extracci√≥n de texto (Azure Document Intelligence)
 ‚Üì
Preprocesamiento
 ‚Üì
Clasificaci√≥n con Azure OpenAI
 ‚Üì
Categor√≠a + Justificaci√≥n (JSON)

Enfoque t√©cnico

La clasificaci√≥n se realiza mediante:

Un deployment de Azure OpenAI configurado en Azure AI Foundry

Un prompt estructurado
Una llamada controlada al endpoint del modelo
Manejo defensivo de la respuesta
Esto garantiza resultados consistentes, trazables y explicables.

codigo main.py

```python
import os
from extract import extract_text_from_pdf
from preprocess import preprocess_text
from classify import classify_text


def process_document(pdf_path):
    """
    Ejecuta el flujo completo de procesamiento y clasificaci√≥n
    de un documento PDF.
    """

    # 1. Extraer texto desde el PDF usando Azure Document Intelligence
    raw_text = extract_text_from_pdf(pdf_path)

    # 2. Preprocesar el texto (normalizaci√≥n b√°sica)
    clean_text = preprocess_text(raw_text)

    # 3. Clasificar el documento usando Azure OpenAI
    classification_result = classify_text(clean_text)

    return classification_result


def process_folder(folder_path):
    """
    Procesa todos los archivos PDF dentro de una carpeta
    y retorna los resultados de clasificaci√≥n.
    """

    results = []

    # Recorrer recursivamente la carpeta de entrada
    for root, _, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(".pdf"):
                pdf_path = os.path.join(root, file)

                # Ejecutar el flujo completo para cada documento
                result = process_document(pdf_path)

                results.append({
                    "archivo": file,
                    "resultado": result
                })

    return results


if __name__ == "__main__":
    # Carpeta de entrada de documentos PDF
    INPUT_FOLDER = "data/pdfs"

    # Ejecutar el procesamiento completo
    classification_results = process_folder(INPUT_FOLDER)

    # Mostrar resultados por consola
    for item in classification_results:
        print(f"Archivo: {item['archivo']}")
        print(f"Categor√≠a: {item['resultado'].get('categoria')}")
        print(f"Justificaci√≥n: {item['resultado'].get('justificacion')}")
        print("-" * 50)
```

‚úî Orquesta todo el pipeline
‚úî Procesa uno o m√∫ltiples PDFs
‚úî Usa extracci√≥n, preprocesamiento y clasificaci√≥n
‚úî Devuelve categor√≠a + justificaci√≥n
‚úî No expone credenciales
‚úî Es simple, claro y defendible

# Actividad 11 ‚Äì Manejo de documentos largos

En esta actividad se implementa una estrategia de manejo de documentos largos para garantizar que el texto enviado al modelo de lenguaje no exceda los l√≠mites de contexto del LLM.

Se utiliza una t√©cnica de chunking, que consiste en dividir el texto en fragmentos controlados antes de la inferencia.

Los modelos de lenguaje tienen un l√≠mite m√°ximo de tokens por solicitud.
Los documentos PDF extensos (contratos largos, informes, resoluciones) pueden superar f√°cilmente ese l√≠mite.

**Estrategia aplicada**

La soluci√≥n implementa un chunking simple y efectivo, basado en:

Divisi√≥n del texto por longitud aproximada
Procesamiento de fragmentos independientes
Consolidaci√≥n del resultado final


Enfoque t√©cnico

El texto completo es dividido en fragmentos (‚Äúchunks‚Äù)
Cada fragmento se env√≠a al LLM
Se obtiene una clasificaci√≥n parcial
Se consolida una clasificaci√≥n final
Implementaci√≥n del chunking

üìÑ Archivo: src/chunking.py

```python
def chunk_text(text, max_length=3000):
    """
    Divide un texto largo en fragmentos de tama√±o controlado.
    """

    chunks = []
    start = 0

    while start < len(text):
        end = start + max_length
        chunks.append(text[start:end])
        start = end

    return chunks
```
Estrategia de consolidaci√≥n

Para la prueba t√©cnica, se utiliza una estrategia simple:

Se toma la categor√≠a m√°s frecuente

Se conserva una justificaci√≥n representativa

üìå Esto puede evolucionar a:

Prompts de resumen

Votaci√≥n ponderada

Razonamiento jer√°rquico

Evidencia de manejo de longitud

‚úî Implementaci√≥n expl√≠cita de chunking
‚úî C√≥digo modular y reutilizable
‚úî Prevenci√≥n de l√≠mites de contexto
‚úî Manejo correcto de documentos extensos

Justificaci√≥n de la soluci√≥n

Se eligi√≥ chunking simple porque:

Es claro y f√°cil de entender
No depende de librer√≠as externas
Funciona con cualquier modelo GPT
Es suficiente para el alcance de la prueba

Para manejar documentos extensos, se implement√≥ una estrategia de chunking que divide el texto en fragmentos controlados antes de enviarlos al modelo de lenguaje, evitando exceder los l√≠mites de contexto y garantizando una clasificaci√≥n robusta.
