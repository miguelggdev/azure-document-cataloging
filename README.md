# Proyecto ‚Äì Entrenamiento de un modelo ML con Azure Machine Learning y scikit-learn

## üìå Descripci√≥n
Este proyecto demuestra el uso de **Azure AI**para para dise√±ar, implementar y justificar una soluci√≥n de clasificaci√≥n autom√°tica de documentos PDF, utilizando Modelos de Lenguaje de Gran Escala (LLMs), 
Consumidos / desplegados en Microsoft Azure.

## Caso de uso del proyecyo 

Una organizaci√≥n recibe diariamente documentos en formato PDF (oficios, contratos, resoluciones, quejas, informes t√©cnicos, etc.) que deben ser clasificados manualmente para su gesti√≥n interna. 

**Problemas actuales:**

- Procesos manuales lentos
- Errores de clasificaci√≥n
- Dificultad para escalar el volumen documental
- Dependencia de personal especializado

**Necesidad**
Automatizar la clasificaci√≥n inicial de documentos para facilitar su enrutamiento, priorizaci√≥n y an√°lisis posterior.

## Objetivos del proyecto

Dise√±ar una soluci√≥n basada en LLMs que permita:

- Extraer texto desde documentos PDF
- Analizar su contenido sem√°ntico
- Clasificar autom√°ticamente el documento en una categor√≠a definida
- Generar una justificaci√≥n legible de la clasificaci√≥n
- Ejecutarse Azure, de forma reproducible

**Categor√≠as de clasificaci√≥n**
Se puede usar estas u otras (deben documentarse):

- Queja / Reclamo
- Contrato
- Resoluci√≥n administrativa
- Informe t√©cnico
- Comunicaci√≥n interna

## Actividades de desarrollo

# Actividad 1
Selecci√≥n del ambiente de ejecuci√≥n

Para el desarrollo de este proyecto **se eligi√≥ la modalidad Azure, utilizando servicios de Azure AI**, principalmente Azure Document Intelligence para la extracci√≥n de texto desde documentos PDF y Azure OpenAI para el an√°lisis sem√°ntico y la clasificaci√≥n autom√°tica.

Esta modalidad permite cumplir con los requerimientos del caso de uso, manteniendo una arquitectura empresarial, segura y escalable.

# Actividad 2 Dise√±o de la soluci√≥n (funcional)

**Contexto del problema**

La organizaci√≥n recibe diariamente documentos en formato PDF (quejas, contratos, resoluciones, informes, comunicaciones internas) que deben ser clasificados manualmente,  lo cual genera un cuello de botella en la clasificacion de documentos generando demoras, errores y dificultad para escalar el proceso.

**Objetivo funcional**

Realizar una solucion de IA con Azure para automatizar la clasificaci√≥n inicial de documentos PDF para lograr facilitar su gesti√≥n, priorizaci√≥n y an√°lisis posterior.

**Soluci√≥n propuesta**

Se propone desarrollar una soluci√≥n que permita:

- Cargar documentos PDF de diferentes tipos
- Extraer autom√°ticamente el texto del documento
- Analizar su contenido sem√°ntico
- Clasificar el documento en una categor√≠a definida
- Generar una justificaci√≥n clara de la clasificaci√≥n

De esta manera, se reduce la intervenci√≥n manual y se mejora la eficiencia del proceso documental.

# Actividad 3 Dise√±o de la soluci√≥n (t√©cnico)

La soluci√≥n se basa en una arquitectura simple y modular que separa claramente cada responsabilidad del proceso:

- Extracci√≥n de texto:
Se utiliza Azure AI Document Intelligence para extraer texto desde documentos PDF.

- Preprocesamiento:
El texto extra√≠do se limpia y normaliza para facilitar su an√°lisis.

- An√°lisis sem√°ntico y clasificaci√≥n:
El texto procesado se env√≠a a un modelo de lenguaje de Azure OpenAI, el cual clasifica el documento y genera una justificaci√≥n basada en su contenido.

- Generaci√≥n de resultados:
El resultado final se estructura en un formato legible (JSON), que puede ser utilizado por otros sistemas o procesos posteriores.

![Flujo-de-trabajo](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/flujo_trabajo.png)

# Actividad 4 ‚Äì Selecci√≥n y uso del LLM

Modelo seleccionado

Se utiliza un modelo de lenguaje grande (LLM) proporcionado por Azure OpenAI, como GPT-4 o GPT-4o.

**Justificaci√≥n del uso del LLM**

Permite comprender el contenido sem√°ntico del documento, no solo palabras clave

Se adapta a diferentes tipos de documentos sin necesidad de entrenamiento adicional

Genera clasificaciones explicables y coherentes

Reduce la necesidad de reglas r√≠gidas o modelos tradicionales de clasificaci√≥n

Azure OpenAI ofrece adem√°s ventajas a nivel de seguridad, cumplimiento y control del acceso, lo cual es clave en entornos empresariales.

# Actividad 5 ‚Äì Configuraci√≥n del entorno

Definici√≥n del entorno

PAra este proyecto el entorno de ejecucion se define como Servicio de IA gestionado (PaaS), usando Azure AI Document Intelligence yAzure OpenAI.

El codigo se desarrolla para python, pero se ejecuta y procesa con Azure 

Dependencias declaradas en requirements.txt
Manejo de credenciales mediante variables de entorno
Separaci√≥n clara entre c√≥digo fuente, datos de entrada y resultados

**Creaci√≥n del Resource Group (Azure CLI)**

Crear un grupo de recursos para la soluci√≥n

```bash
az group create \
  --name rg-ia-clasificacion-documental \
  --location eastus
```
![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/grupo_recursos.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/grupo_recursos2.jpg)
**Gesti√≥n de dependencias**

El proyecto est√° estructurado para ejecutarse en un entorno Python y define sus dependencias en el archivo requirements.txt, lo que permite recrear el entorno de forma controlada:
```python
openai
azure-ai-formrecognizer
python-dotenv
tiktoken
```
Estas librer√≠as permiten:

- Conectarse a Azure OpenAI
- Extraer texto desde PDFs usando Azure AI
- Manejar variables de entorno de forma segura
- Controlar la longitud del texto enviado al modelo

Manejo de variables de entorno

Las credenciales de los servicios Azure se gestionan mediante variables de entorno, evitando la exposici√≥n de informaci√≥n sensible en el c√≥digo.

El proyecto incluye un archivo de referencia .env.example:

```python
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_KEY=
AZURE_OPENAI_DEPLOYMENT=
FORM_RECOGNIZER_ENDPOINT=
FORM_RECOGNIZER_KEY=
```

El archivo real .env no se versiona y se encuentra incluido en el archivo .gitignore.
Preparaci√≥n del entorno (documentado)

En un escenario de ejecuci√≥n, el entorno se preparar√≠a de la siguiente forma:

**Crear Azure AI Document Intelligence (OCR)**

üìç Azure Portal
Buscar Azure AI Document Intelligence
Crear nuevo recurso
Seleccionar:
Resource Group: rg-ia-clasificacion-pdf
Regi√≥n
Plan: Standard (S0)
Crear

üìå Esto es parte del entorno de ejecuci√≥n, porque aqu√≠ se ejecuta el OCR.

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/documentIntell.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/documentIntel2.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/documentIntel3.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/documentIntel4.jpg)



**Crear Azure OpenAI (LLM)**
Azure Portal

Buscar Azure OpenAI
Crear recurso
Seleccionar:
Resource Group: rg-ia-clasificacion-pdf
Regi√≥n
Crear

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/OpenAI.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/OpenAI2.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/OpenAI3.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/OpenAI4.jpg)

Ir al Portal de Foundry


![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/project.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry.jpg)


 Selecciona el proyecto correcto

Una vez dentro de Foundry:

Arriba o en el panel inicial, selecciona:

Subscription: Azure subscription 1

Project: projectdocumental

Resource Group: rg-ia-clasificacion-documental

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry2.jpg)

**Ir a Deployments / Implementaciones**

En el men√∫ izquierdo de Foundry busca:

Deployments

Model deployments

Implementaciones

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry3.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry4.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry5.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry6.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry7.jpg)

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/foundry8.jpg)


![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/keys_endpoinst.jpg)

# Actividad 6 Ingesta de documentos PDF

La soluci√≥n implementa un mecanismo de ingesta de documentos PDF que permite cargar uno o varios archivos para su posterior procesamiento autom√°tico.
Para efectos de esta prueba t√©cnica, la ingesta se realiza desde una estructura de carpetas local dentro del repositorio, la cual simula el origen de los documentos que recibe la organizaci√≥n.

Este enfoque permite:
Validar f√°cilmente el funcionamiento de la soluci√≥n
Procesar m√∫ltiples documentos en un solo flujo
Mantener la soluci√≥n simple, reproducible y alineada con el alcance de la prueba

Enfoque t√©cnico de la ingesta
El proceso de ingesta consiste en:
Recorrer de forma autom√°tica la carpeta data/pdfs
Identificar todos los archivos con extensi√≥n .pdf
Enviar cada documento al flujo de extracci√≥n y clasificaci√≥n
Procesar los documentos de manera independiente
Este enfoque permite escalar f√°cilmente el n√∫mero de documentos sin modificar el c√≥digo.
Estructura de entrada de documentos

Los documentos PDF se organizan en una carpeta dedicada dentro del proyecto, clasificados inicialmente por tipo √∫nicamente con fines de prueba y validaci√≥n.

![grupo-drecursos](https://github.com/miguelggdev/azureML/blob/main/project-01-azureml-sklearn/screenshots/ingesta.jpg)



# Actividad 7 ‚Äì Clasificaci√≥n documental con Azure OpenAI

En esta actividad se implementa la clasificaci√≥n autom√°tica de documentos utilizando Azure OpenAI, a partir del texto previamente extra√≠do desde los archivos PDF.

El modelo de lenguaje analiza el contenido completo del documento y determina:

La categor√≠a documental

Una justificaci√≥n breve basada en el contenido

Este enfoque permite realizar una clasificaci√≥n sem√°ntica, superando las limitaciones de reglas est√°ticas o palabras clave.

Categor√≠as definidas

Las categor√≠as manejadas por la soluci√≥n son:

Contrato
Queja
Resoluci√≥n
Informe
Comunicaci√≥n
Otro
Estas categor√≠as pueden ampliarse sin modificar la arquitectura general.

Enfoque t√©cnico

El flujo de clasificaci√≥n se basa en:

Recepci√≥n del texto extra√≠do del PDF

Env√≠o del texto a un deployment de Azure OpenAI

Uso de un prompt estructurado para guiar la respuesta

Obtenci√≥n de una salida controlada y explicable

9
Dise√±o del prompt
Crear un prompt estructurado para clasificaci√≥n con LLM



# Actividad 7  8 ‚Äì Preprocesamiento del texto

En esta actividad se realiza el preprocesamiento b√°sico del texto extra√≠do desde los documentos PDF, con el objetivo de normalizar y preparar la informaci√≥n antes de enviarla al modelo de lenguaje para inferencia.

El preprocesamiento permite:

Reducir ruido en el texto
Garantizar entradas consistentes al modelo
Mejorar la calidad de la clasificaci√≥n
Alcance del preprocesamiento
Para la prueba t√©cnica se implementa un preprocesamiento ligero, alineado con buenas pr√°cticas y sin sobreingenier√≠a.

Incluye:

Limpieza de espacios innecesarios
Normalizaci√≥n b√°sica del texto
Preparaci√≥n del contenido para inferencia

No se realiza:

Tokenizaci√≥n avanzada
Eliminaci√≥n sem√°ntica
An√°lisis ling√º√≠stico profundo

Enfoque t√©cnico

El texto preprocesado se obtiene a partir del texto plano generado por Azure Document Intelligence y se procesa mediante funciones simples en Python, manteniendo la trazabilidad del contenido original.

src/preprocess.py

```python
import re

def preprocess_text(text):
    """
    Normaliza el texto extra√≠do del documento para
    dejarlo listo para inferencia con el modelo de lenguaje.
    """

    # Elimina saltos de l√≠nea
    text = text.replace("\n", " ")

    # Reemplaza m√∫ltiples espacios por uno solo
    text = re.sub(r"\s+", " ", text)

    # Elimina espacios al inicio y al final
    text = text.strip()

    return text
```
# Actividad 9

En esta actividad se dise√±a un prompt estructurado y explicable para guiar al modelo de lenguaje (Azure OpenAI) en la clasificaci√≥n documental.

El prompt define expl√≠citamente:

El rol del modelo

Las categor√≠as permitidas

El formato de salida

El contexto del documento

Esto garantiza respuestas:

Consistentes

Interpretables

F√°ciles de auditar

Objetivo del prompt

El prompt tiene como objetivo que el modelo:

Analice el contenido completo del documento

Determine la categor√≠a documental m√°s adecuada

Explique brevemente la raz√≥n de la clasificaci√≥n

Retorne una salida estructurada y procesable

Principios de dise√±o del prompt

El dise√±o del prompt sigue buenas pr√°cticas para LLMs:

Claridad: instrucciones directas y sin ambig√ºedad

Restricci√≥n: categor√≠as cerradas

Estructura: salida en formato JSON

Explicabilidad: justificaci√≥n obligatoria

Prompt definitivo utilizado en la soluci√≥n

üìå Este prompt es el que se utiliza en classify.py

*Eres un asistente experto en clasificaci√≥n documental.

Analiza el siguiente texto y clasif√≠calo en UNA de las siguientes categor√≠as:
- Contrato
- Queja
- Resoluci√≥n
- Informe
- Comunicaci√≥n
- Otro

Devuelve √∫nicamente un JSON con esta estructura:
{
  "categoria": "<categoria>",
  "justificacion": "<explicacion breve basada en el contenido>"
}

Texto del documento:
{document_text}*

Explicaci√≥n del prompt (parte por parte)
1Ô∏è‚É£ Definici√≥n del rol

‚ÄúEres un asistente experto en clasificaci√≥n documental‚Äù

üîπ Orienta el comportamiento del modelo
üîπ Reduce respuestas creativas o irrelevantes

2Ô∏è‚É£ Definici√≥n expl√≠cita de categor√≠as

üîπ Evita clasificaciones abiertas
üîπ Facilita evaluaci√≥n y m√©tricas
üîπ Permite extender categor√≠as sin cambiar arquitectura

3Ô∏è‚É£ Formato de salida estructurado
{
  "categoria": "...",
  "justificacion": "..."
}


üîπ Permite parsing autom√°tico
üîπ Mejora trazabilidad
üîπ Facilita auditor√≠a del resultado

4Ô∏è‚É£ Inclusi√≥n del texto completo

üîπ El modelo tiene todo el contexto
üîπ Permite inferencia sem√°ntica real
üîπ Evita dependencias de reglas o keywords

Justificaci√≥n de la soluci√≥n

Se eligi√≥ un prompt estructurado porque:

Reduce variabilidad del modelo

Aumenta la confiabilidad del resultado

Facilita integraci√≥n con otros sistemas

Permite explicar cada decisi√≥n del modelo

Este dise√±o cumple principios de IA explicable (XAI).

Resultado de la actividad

‚úî Prompt claro y documentado
‚úî Salida estructurada
‚úî Clasificaci√≥n explicable
‚úî F√°cil de mantener y extender

üìå Texto recomendado para el README

Se dise√±√≥ un prompt estructurado para la clasificaci√≥n documental, definiendo roles, categor√≠as cerradas y un formato de salida en JSON, garantizando resultados explicables y consistentes por parte del modelo de lenguaje.

# Actividad 10

En esta actividad se ejecuta la clasificaci√≥n final de los documentos utilizando un modelo de lenguaje desplegado en Azure OpenAI.
El texto, previamente extra√≠do y preprocesado, es enviado al LLM, el cual retorna:

La categor√≠a documental

Una justificaci√≥n explicable

La respuesta del modelo se recibe en un formato estructurado (JSON), permitiendo su uso posterior en sistemas de almacenamiento, visualizaci√≥n o automatizaci√≥n.

Flujo completo de clasificaci√≥n

El flujo de esta actividad integra todas las etapas anteriores:

PDF
 ‚Üì
Extracci√≥n de texto (Azure Document Intelligence)
 ‚Üì
Preprocesamiento
 ‚Üì
Clasificaci√≥n con Azure OpenAI
 ‚Üì
Categor√≠a + Justificaci√≥n (JSON)

Enfoque t√©cnico

La clasificaci√≥n se realiza mediante:

Un deployment de Azure OpenAI configurado en Azure AI Foundry

Un prompt estructurado

Una llamada controlada al endpoint del modelo

Manejo defensivo de la respuesta

Esto garantiza resultados consistentes, trazables y explicables.

codigo main.py

```python
import os
from extract import extract_text_from_pdf
from preprocess import preprocess_text
from classify import classify_text


def process_document(pdf_path):
    """
    Ejecuta el flujo completo de procesamiento y clasificaci√≥n
    de un documento PDF.
    """

    # 1. Extraer texto desde el PDF usando Azure Document Intelligence
    raw_text = extract_text_from_pdf(pdf_path)

    # 2. Preprocesar el texto (normalizaci√≥n b√°sica)
    clean_text = preprocess_text(raw_text)

    # 3. Clasificar el documento usando Azure OpenAI
    classification_result = classify_text(clean_text)

    return classification_result


def process_folder(folder_path):
    """
    Procesa todos los archivos PDF dentro de una carpeta
    y retorna los resultados de clasificaci√≥n.
    """

    results = []

    # Recorrer recursivamente la carpeta de entrada
    for root, _, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(".pdf"):
                pdf_path = os.path.join(root, file)

                # Ejecutar el flujo completo para cada documento
                result = process_document(pdf_path)

                results.append({
                    "archivo": file,
                    "resultado": result
                })

    return results


if __name__ == "__main__":
    # Carpeta de entrada de documentos PDF
    INPUT_FOLDER = "data/pdfs"

    # Ejecutar el procesamiento completo
    classification_results = process_folder(INPUT_FOLDER)

    # Mostrar resultados por consola
    for item in classification_results:
        print(f"Archivo: {item['archivo']}")
        print(f"Categor√≠a: {item['resultado'].get('categoria')}")
        print(f"Justificaci√≥n: {item['resultado'].get('justificacion')}")
        print("-" * 50)
```


        ‚úÖ Qu√© hace este main.py (resumen claro)

‚úî Orquesta todo el pipeline
‚úî Procesa uno o m√∫ltiples PDFs
‚úî Usa extracci√≥n, preprocesamiento y clasificaci√≥n
‚úî Devuelve categor√≠a + justificaci√≥n
‚úî No expone credenciales
‚úî Es simple, claro y defendible

‚úÖ Actividad 11 ‚Äì Manejo de documentos largos
Descripci√≥n de la actividad

En esta actividad se implementa una estrategia de manejo de documentos largos para garantizar que el texto enviado al modelo de lenguaje no exceda los l√≠mites de contexto del LLM.

Para ello, se utiliza una t√©cnica de chunking, que consiste en dividir el texto en fragmentos controlados antes de la inferencia.

¬øPor qu√© es necesario el manejo de longitud?

Los modelos de lenguaje tienen un l√≠mite m√°ximo de tokens por solicitud.
Los documentos PDF extensos (contratos largos, informes, resoluciones) pueden superar f√°cilmente ese l√≠mite.

Sin una estrategia de chunking:

‚ùå Fallos por exceso de tokens

‚ùå P√©rdida de informaci√≥n

‚ùå Resultados inconsistentes

Estrategia aplicada

La soluci√≥n implementa un chunking simple y efectivo, basado en:

Divisi√≥n del texto por longitud aproximada

Procesamiento de fragmentos independientes

Consolidaci√≥n del resultado final

üìå Esta estrategia es suficiente y defendible para una prueba t√©cnica.

Enfoque t√©cnico

El texto completo es dividido en fragmentos (‚Äúchunks‚Äù)

Cada fragmento se env√≠a al LLM

Se obtiene una clasificaci√≥n parcial

Se consolida una clasificaci√≥n final

Implementaci√≥n del chunking

üìÑ Archivo: src/chunking.py

```python
def chunk_text(text, max_length=3000):
    """
    Divide un texto largo en fragmentos de tama√±o controlado.
    """

    chunks = []
    start = 0

    while start < len(text):
        end = start + max_length
        chunks.append(text[start:end])
        start = end

    return chunks
```
Estrategia de consolidaci√≥n

Para la prueba t√©cnica, se utiliza una estrategia simple:

Se toma la categor√≠a m√°s frecuente

Se conserva una justificaci√≥n representativa

üìå Esto puede evolucionar a:

Prompts de resumen

Votaci√≥n ponderada

Razonamiento jer√°rquico

Evidencia de manejo de longitud

‚úî Implementaci√≥n expl√≠cita de chunking
‚úî C√≥digo modular y reutilizable
‚úî Prevenci√≥n de l√≠mites de contexto
‚úî Manejo correcto de documentos extensos

Justificaci√≥n de la soluci√≥n

Se eligi√≥ chunking simple porque:

Es claro y f√°cil de entender

No depende de librer√≠as externas

Funciona con cualquier modelo GPT

Es suficiente para el alcance de la prueba

La arquitectura queda preparada para estrategias m√°s avanzadas.

üìå Texto recomendado para el README

Para manejar documentos extensos, se implement√≥ una estrategia de chunking que divide el texto en fragmentos controlados antes de enviarlos al modelo de lenguaje, evitando exceder los l√≠mites de contexto y garantizando una clasificaci√≥n robusta.

üéØ Estado

üëâ Actividad 11: COMPLETADA

üîé Nota importante (esto suma puntos)

Puedes mencionar en la entrevista:

‚ÄúEl chunking se aplica solo cuando la longitud del documento lo requiere, manteniendo eficiencia y control de costos.‚Äù